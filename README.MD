<h1>Руководство по Stream</h1>

Это руководство раскрывает основы написания node.js программ с использованием потоков. 

<h2>Введение</h2>

Концепция потоков пришла к нам почти с момента зарождения unix и зарекомендовала себя как надежный способ построения больших систем из небольших компонентов, чья функция -- делать хорошо всего одну вещь. В unix поток можно реализовать при помощи shell путем добавления | pipe. В node.js присутствует встроенный модуль 'stream', используемый в ядре node, но его можно использовать и в пользовательских модулях. Как и в unix, модуль 'stream' прежде всего включает в состав оператор .pipe(), благодаря которому вы имеете возможность написать некий регулятор.

Потоки помогают разделить ваши задачи, поскольку ограничивают зону поверхности выполнения в последовательных интерфейсах, что способствует переиспользованию кода. В дальнейшем можно перенаправить выход одного потока на вход другого и использовать библиотеки, которые позволяют оперировать потоками на более высоком уровне абстракции. 

Потоки - это очень важный компонент <a href="https://michaelochurch.wordpress.com/2012/08/15/what-is-spaghetti-code/">дизайна маленьких программ</a> философии unix, но есть и другие важные абстракции, которые стоит рассмотреть. Просто запомните, что <a href="https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B4%D0%BE%D0%BB%D0%B3">технический долг</a> - это враг и всегда необходимо искать лучшие абстракции для решаемой задачи.

<h2>Почему необходимо использовать потоки?</h2>

Операции ввода/вывода в node.js являются асинхронными, поэтому взаимодействие с диском и сетью включают в себя передачу коллбек-функций. У вас может возникнуть соблазн написать код, подобный этому: 

<code>
	var http = require('http');
	var fs = require('fs');

	var server = http.createServer(function (req, res) {
	    fs.readFile(__dirname + '/data.txt', function (err, data) {
	        res.end(data);
	    });
	});
	server.listen(8000);
</code> 

Этот код будет работать, но он довольно громоздкий и сохраняет целый файл data.txt в памяти для каждого запроса, перед тем как отдать результат клиенту. Если data.txt очень большой, ваша программа будет съедать очень много памяти, так как она используется многими пользователями одновременно, особенно заметно это будет пользователям с медленным соединением. 

Из-за этого обстоятельства обедняется UX, поскольку пользователь должен ждать пока весь файл на сервере попадет в буфер и только после этого получит его себе. 

К счастью, оба аргумента req и res являются потоками, и это можно использовать для написания нашего файлового сервера. Более продуктивно в данном случае использовать метод fs.createReadStream(), а не fs.readFile():

<code>
	var http = require('http');
	var fs = require('fs');

	var server = http.createServer(function (req, res) {
	    var stream = fs.createReadStream(__dirname + '/data.txt');
	    stream.pipe(res);
	});
	server.listen(8000);
</code>

Метод .pipe() в этом примере заботится о прослушивании для событий 'data' и 'end' из метода fs.createReadStream(). Этот код еще не является идеальным, но не смотря на это, сейчас файл data.txt будет поступать клиенту порциями по мере их поступления с диска. 

Используя .pipe(), можно получить и другие приемущества, такие как <a href="http://www.techopedia.com/definition/24131/backpressure">automatically handling backpressure</a> - node.js не будет помещать куски данных в память без нужды, когда удаленный клиент использует очень медленное соединение, например.

Хотите сжать файл? Существуют потоковые модули для того, чтобы это сделать!
<code>
	var http = require('http');
	var fs = require('fs');
	var oppressor = require('oppressor');

	var server = http.createServer(function (req, res) {
	    var stream = fs.createReadStream(__dirname + '/data.txt');
	    stream.pipe(oppressor(req)).pipe(res);
	});
	server.listen(8000);
</code> 

Сейчас файл data.txt сжимается для браузеров, которые поддерживают gzip или Deflate. Мы можем просто воспользоваться модулем oppressor для обработки всего контента.

Однажды изучив stream api, вы сможете просто объединять вместе потоковые модули, как кубики лего или САДОВЫЙ ШЛАНГ, вместо того, чтобы помнить как отправить данные через шаткие непотоковые самодельные API. 

<h2>Основы</h2>

Существуют 5 типов потоков:
	<ul>
		<li>readable</li>
		<li>writable</li>
		<li>transform</li>
		<li>duplex</li>
		<li>"classic"</li>
	</ul>

<h3>pipe</h3>	
Все типы потоков используют .pipe() для объединения ввода и вывода. 

.pipe() - это просто функция, которая принимает readable поток src и перенаправляет вывод в writable поток dst: 

<code>
	src.pipe(dst)
</code>

.pipe(dst) возвращает dst, поэтому можно объединять вместе несколько .pipe():

<code>
	a.pipe(b).pipe(c).pipe(d)
</code>

, тоже самое можно записать так:

<code>
	a.pipe(b);
	b.pipe(c);
	c.pipe(d);
</code>

Это почти тоже самое, что следующая запись в командной строке unix:

<code>
	a | b | c | d
</code>

разница лишь в том, что мы используем node.js вместо shell.

<h3>Потоки для чтения (readable streams)</h3>
Потоки для чтения выводят данные, которые могут быть перенаправлены в поток для записи (writable), transform - потоки или duplex с помощью .pipe(): 

<code>
	readableStream.pipe(dst)
</code>

<h3>Создание потока для чтения (readable stream)</h3>
Давайте создадим поток для чтения!

<code>
	var Readable = require('stream').Readable;

	var rs = new Readable;
	rs.push('beep ');
	rs.push('boop\n');
	rs.push('null');

	rs.pipe(process.stdout);

	$ node read0.js
	beep boop
</code>

rs.push(null) говорит о том, что данные закончили отдаваться. 

Следует помнить, что мы передаем контент в поток для чтения rs (с помощью метода .push()) до того, как перенаправить его (с помощью .pipe()) в поток для вывода (process.stdout), и сообщение о передаче null в поток для чтения должно быть записано до перенаправления в process.stdout.

Это необходимо, поскольку, <code>.push()</code> передает куски данных в поток и они сохраняются в буфере, пока следующее звено потока не будет готово принять их.

Тем не менее, было бы еще лучше, если бы мы могли избежать буферизации данных перед тем, как отдать их и генерировать их только тогда, когда потребитель просит об этом.

Мы можем отдать порцию данных по требованию, если определим функцию ._read: 

<code>
	var Readable = require('stream').Readable;
	var rs = Readable();

	var c = 97;
	rs._read = function(){
		rs.push(String.fromCharCode(c++));
		if(c>'z'.charCodeAt(0)) rs.push(null);
	};
</code>

<code>
	rs.pipe(process.stdout);

	$ node read1.js
	abcdefghijklmnopqrstuvwxyz
</code>

В данном случае, мы передаем буквы с 'a' по 'z', но только после того, как потребитель готов прочитать их.

Функция _read принимает предварительный параметр size в качестве первого аргумента, который определяет размер порций в байтах, который готов принимать потребитель, но наша функция проигнорирует size, если потребитель его запросит. 

Следует помнить, что вы можете также использовать метод util.inherits() встроенного модуля 'util' для того, чтобы наследовать Readable. Но такой подход не очень хорошо подходит для примеров, поскольку создает дополнительную сложность в понимании. 

Для того, чтобы показать, что функция _read в настоящее время была вызвана при запросе потребителя, мы можем немного изменить наш код readable потока, добавив задержку:

<code>
	var Readable = require('stream').Readable;
	var rs = Readable();

	var c = 97 - 1;

	rs._read = function () {
	    if (c >= 'z'.charCodeAt(0)) return rs.push(null);

	    setTimeout(function () {
	        rs.push(String.fromCharCode(++c));
	    }, 100);
	};

	rs.pipe(process.stdout);

	process.on('exit', function () {
	    console.error('\n_read() called ' + (c - 97) + ' times');
	});
	process.stdout.on('error', process.exit);
</code>

В результате работы этой программы, в консоли выйдет сообщение, о том, что функция _read() вызвана 5 раз, когда мы запросили только 5 байт вывода:

<code>
	$ node read2.js | head -c5
	abcde
	_read() called 5 times
</code>

Задержка, созданная с помошью setTimeout() необходима, поскольку операционной системе требуется некотороe время, чтобы послать соответствующий сигнал о закрытии pipe.

Обработчик <code>process.stdout.on('error', fn)</code> также необходим, поскольку операционная система посылает SIGPIPE к нашему process, когда <code>head</code> больше не интересует вывод нашей программы, которая принимает EPIPE ошибку в process.stdout.

Эти дополнительные осложнения нужны, когда происходят взаимодействия с внешней операционной системой, но когда потоки взаимодействуют внутри node, этого не требуется. 

Если вы хотите создать поток для чтения, который принимает произвольные данные, а не только данные типа string и buffer, убедитесь, что создали ваш readable-поток с дополнительным параметром: <code>Readable({ objectMode: true })</code>

